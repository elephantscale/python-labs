{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spacy-Example3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fw99iq_HM5lg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#HASHES\n",
        "  \n",
        "\n",
        "import spacy\n",
        "    \n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"I have a cat\")\n",
        "\n",
        "# Look up the hash for the word \"cat\"\n",
        "cat_hash = ____.____.____[____]\n",
        "print(cat_hash)\n",
        "\n",
        "# Look up the cat_hash to get the string\n",
        "cat_string = ____.____.____[____]\n",
        "print(cat_string)\n",
        "\n",
        "\n",
        "   \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgK2DD1KNWFg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Look up the hash for the string label \"PERSON\"\n",
        "person_hash = ____.____.____[____]\n",
        "print(person_hash)\n",
        "\n",
        "# Look up the person_hash to get the string\n",
        "person_string = ____.____.____[____]\n",
        "print(person_string)\n",
        "\n",
        "\n",
        "\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHkWCYNdNYIv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# Import the Doc class\n",
        "from ____ import ____\n",
        "\n",
        "# Desired text: \"spaCy is cool!\"\n",
        "words = [\"spaCy\", \"is\", \"cool\", \"!\"]\n",
        "spaces = [True, True, False, False]\n",
        "\n",
        "# Create a Doc from the words and spaces\n",
        "doc = ____(____, words=words, spaces=spaces)\n",
        "print(doc.text)\n",
        "\n",
        "j"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eW97Tkx3NxP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Desired text: \"Go, get started!\"\n",
        "words = [\"Go\", \",\", \"get\", \"started\", \"!\"]\n",
        "spaces = [____, ____, ____, ____, ____]\n",
        "\n",
        "# Create a Doc from the words and spaces\n",
        "doc = ____(____, ____=____, ____=____)\n",
        "print(doc.text)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8lj-3fDN1Xr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# Desired text: \"Oh, really?!\"\n",
        "words = [____, ____, ____, ____, ____]\n",
        "spaces = [____, ____, ____, ____, ____]\n",
        "\n",
        "# Create a Doc from the words and spaces\n",
        "doc = ____(____, ____=____, ____=____)\n",
        "print(doc.text)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILyR3xGAN7Qv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from spacy.lang.en import English\n",
        "\n",
        "nlp = English()\n",
        "\n",
        "# Import the Doc and Span classes\n",
        "from spacy.____ import ____, ____\n",
        "\n",
        "words = [\"I\", \"like\", \"David\", \"Bowie\"]\n",
        "spaces = [True, True, True, False]\n",
        "\n",
        "# Create a doc from the words and spaces\n",
        "doc = ____(____, ____, ____)\n",
        "print(doc.text)\n",
        "\n",
        "# Create a span for \"David Bowie\" from the doc and assign it the label \"PERSON\"\n",
        "span = ____(____, ____, ____, label=____)\n",
        "print(span.text, span.label_)\n",
        "\n",
        "# Add the span to the doc's entities\n",
        "____.____ = [____]\n",
        "\n",
        "# Print entities' text and labels\n",
        "print([(ent.text, ent.label_) for ent in doc.ents])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWiXPQeYOHEB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"Berlin is a nice city\")\n",
        "\n",
        "# Get all tokens and part-of-speech tags\n",
        "token_texts = [token.text for token in doc]\n",
        "pos_tags = [token.pos_ for token in doc]\n",
        "\n",
        "for index, pos in enumerate(pos_tags):\n",
        "    # Check if the current token is a proper noun\n",
        "    if pos == \"PROPN\":\n",
        "        # Check if the next token is a verb\n",
        "        if pos_tags[index + 1] == \"VERB\":\n",
        "            result = token_texts[index]\n",
        "            print(\"Found proper noun before a verb:\", result)\n",
        "            \n",
        "            \n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtZli9kfOJwn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "            \n",
        "            \n",
        "            \n",
        "# Load the en_core_web_md model\n",
        "nlp = ____\n",
        "\n",
        "# Process a text\n",
        "doc = nlp(\"Two bananas in pyjamas\")\n",
        "\n",
        "# Get the vector for the token \"bananas\"\n",
        "bananas_vector = ____.____\n",
        "print(bananas_vector)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7PDGlMQOhwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "doc1 = nlp(\"It's a warm summer day\")\n",
        "doc2 = nlp(\"It's sunny outside\")\n",
        "\n",
        "# Get the similarity of doc1 and doc2\n",
        "similarity = ____.____(____)\n",
        "print(similarity)\n",
        "\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "doc = nlp(\"TV and books\")\n",
        "token1, token2 = doc[0], doc[2]\n",
        "\n",
        "# Get the similarity of the tokens \"TV\" and \"books\"\n",
        "similarity = ____.____(____)\n",
        "print(similarity)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GNNDTsHOkNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "doc = nlp(\"This was a great restaurant. Afterwards, we went to a really nice bar.\")\n",
        "\n",
        "# Create spans for \"great restaurant\" and \"really nice bar\"\n",
        "span1 = ____\n",
        "span2 = ____\n",
        "\n",
        "# Get the similarity of the spans\n",
        "similarity = ____.____(____)\n",
        "print(similarity)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ql2mqDfjOxvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\n",
        "    \"Twitch Prime, the perks program for Amazon Prime members offering free \"\n",
        "    \"loot, games and other benefits, is ditching one of its best features: \"\n",
        "    \"ad-free viewing. According to an email sent out to Amazon Prime members \"\n",
        "    \"today, ad-free viewing will no longer be included as a part of Twitch \"\n",
        "    \"Prime for new members, beginning on September 14. However, members with \"\n",
        "    \"existing annual subscriptions will be able to continue to enjoy ad-free \"\n",
        "    \"viewing until their subscription comes up for renewal. Those with \"\n",
        "    \"monthly subscriptions will have access to ad-free viewing until October 15.\"\n",
        ")\n",
        "\n",
        "# Create the match patterns\n",
        "pattern1 = [{\"LOWER\": \"Amazon\"}, {\"IS_TITLE\": True, \"POS\": \"PROPN\"}]\n",
        "pattern2 = [{\"LOWER\": \"ad-free\"}, {\"POS\": \"NOUN\"}]\n",
        "\n",
        "# Initialize the Matcher and add the patterns\n",
        "matcher = Matcher(nlp.vocab)\n",
        "matcher.add(\"PATTERN1\", None, pattern1)\n",
        "matcher.add(\"PATTERN2\", None, pattern2)\n",
        "\n",
        "# Iterate over the matches\n",
        "for match_id, start, end in matcher(doc):\n",
        "    # Print pattern string name and text of matched span\n",
        "    print(doc.vocab.strings[match_id], doc[start:end].text)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9qLbqISOz1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "import json\n",
        "from spacy.lang.en import English\n",
        "\n",
        "with open(\"exercises/countries.json\") as f:\n",
        "    COUNTRIES = json.loads(f.read())\n",
        "\n",
        "nlp = English()\n",
        "doc = nlp(\"Czech Republic may help Slovakia protect its airspace\")\n",
        "\n",
        "# Import the PhraseMatcher and initialize it\n",
        "from spacy.____ import ____\n",
        "\n",
        "matcher = ____(____)\n",
        "\n",
        "# Create pattern Doc objects and add them to the matcher\n",
        "# This is the faster version of: [nlp(country) for country in COUNTRIES]\n",
        "patterns = list(nlp.pipe(COUNTRIES))\n",
        "matcher.add(\"COUNTRY\", None, *patterns)\n",
        "\n",
        "# Call the matcher on the test document and print the result\n",
        "matches = ____(____)\n",
        "print([doc[start:end] for match_id, start, end in matches])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeVDp_FCSBU7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "from spacy.lang.en import English\n",
        "from spacy.matcher import PhraseMatcher\n",
        "from spacy.tokens import Span\n",
        "import json\n",
        "\n",
        "with open(\"exercises/countries.json\") as f:\n",
        "    COUNTRIES = json.loads(f.read())\n",
        "with open(\"exercises/country_text.txt\") as f:\n",
        "    TEXT = f.read()\n",
        "    \n",
        "nlp = English()\n",
        "matcher = PhraseMatcher(nlp.vocab)\n",
        "patterns = list(nlp.pipe(COUNTRIES))\n",
        "matcher.add(\"COUNTRY\", None, *patterns)\n",
        "\n",
        "# Create a doc and find matches in it\n",
        "doc = ____\n",
        "\n",
        "# Iterate over the matches\n",
        "for match_id, start, end in matcher(doc):\n",
        "    # Create a Span with the label for \"GPE\"\n",
        "    span = ____(____, ____, ____, label=____)\n",
        "    \n",
        "    # Overwrite the doc.ents and add the span\n",
        "    doc.ents = list(doc.ents) + [____]\n",
        "    \n",
        "    # Get the span's root head token\n",
        "    span_root_head = ____.____.____\n",
        "    # Print the text of the span root's head token and the span text\n",
        "    print(span_root_head.____, \"-->\", span.text)\n",
        "    \n",
        "# Print the entities in the document\n",
        "print([(ent.text, ent.label_) for ent in doc.ents if ent.label_ == \"GPE\"])\n",
        "                                                   "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}